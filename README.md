# 文本检索实验报告
## 一、重要文件介绍
- `GUI.py`: 用户端
- `local_server.ipynb`: 服务器端
- `dataprocessing.ipynb`: 数据处理相关操作
- `wordseq.txt`: 词表，都使用此文件中单词顺序
- `middlesave.txt`: 对于dataframe的中间存档
- `tfidf.txt`: tfidf矩阵存档
- `sim_article_05.txt`: 相似文章id字典
- `synonym.txt`: 相似词字典
## 二、任务完成情况
1. 数据处理
    - `完成于dataprocessing.ipynb`: 读入数据集，对数据集中的文章进行去标点、分词、去除停用词及低频词，并对单词进行标准化
    - `完成于dataprocessing.ipynb`: 构建词典，保存为vocab.txt
2. 检索排序
    - `完成于local_server.ipynb的naive_articleSort()`: 根据输入的检索词检索文章，并对检索到的文章进行初步排序并返回。初步排序方法为：构建tf-idf矩阵，对于每篇文章加总关键词对应值作为相关性得分，按得分从大到小返回。
    - `完成于local_server.ipynb和GUI.py`: 搭建C/S架构，具体情况：
      - 由于单次传送不可过大，每次只传送一篇文章的标题和内容。在传送前先将“共有多少文章需要传送”的数字传送给客户端
      - 在操作过程中发现容易出现粘包问题，因此每次传输时先用`struct.pack()`传送要发送的字符串的大小，接收方使用`struct.unpack()`解包后按照此大小继续接收内容，保证所读取的大小严格等于想读取的大小
3. 排序优化
    -  `完成于local_server.ipynb`: 对于文档-词的TF-IDF矩阵，将每行视为用词语的TF-IDF值表示的文章向量，对该矩阵进行降维操作，得到了低维的文章向量，然后计算得到了文章之间的余弦相似度。更进一步使用HITS算法（将余弦距离<0.5的两篇文章视为相互关联），首先使用上文提到的`naive_articleSort()`方法初步排序，然后取得所得结果，将关联文章加入进来，求得这些文章中每篇的$authority$值，按从大到小排序得到优化的的检索结果。
4. 文章聚类
    - `完成于dataprocessing.ipynb`: 通过`Kmeans`对文章向量进行聚类，并与原数据集中的正确分类进行比较，计算$ Purity $，可达到$ 0.95 $，较为准确。
5. 相似词
    - `完成于dataprocessing.ipynb`: 使用之前得到的TF-IDF矩阵生成词向量，得到词向量计算余弦相似度后取余弦距离$ <0.39 $的词为相似词（此时平均每个词有2个左右的相似词）来挖掘每个词的相似词。结果保存为synonym.txt
6. 模糊匹配
    - `完成于GUI.py`: 向服务器发送$1$或$0$表示模糊匹配或精确匹配
    - `完成于local_server.ipynb`: 读入保存好的相似词词典，若收到$ 1 $，对于输入的检索词，通过拓展相似词的方式进行模糊匹配。利用相似词拓展检索结果集合，并排序。
7. 加分项
    - `完成于GUI.py`: 优化TKinter的功能，使用“精确匹配”“模糊匹配”两个按钮让用户自行选择